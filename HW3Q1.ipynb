{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Henry Ho 304723723\n",
    "\n",
    "Justin Sarenas 304675389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Predicting Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a- Read the dataset file \"Hearts_s.csv\", and assign it to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating an empty dataframe\n",
    "hearts_df = pd.DataFrame()\n",
    "\n",
    "# Reading a CSV file from the web\n",
    "hearts_df = pd.read_csv('https://raw.githubusercontent.com/ellipsclamation/cs4661_data_science/master/Datasets/Heart_s.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b- Check out the dataset. As you can see, the dataset contains a number of features including both contextual and biological factors. The last column \"AHD\" is the label with \"Yes\" meaning that a human subject has Heart Disease, and \"No\" meaning that the subject does not have Heart Disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Gender     ChestPain  RestBP  Chol  RestECG  MaxHR  Oldpeak  \\\n",
      "0     63      f       typical     145   233        2    150      2.3   \n",
      "1     67      f  asymptomatic     160   286        2    108      1.5   \n",
      "2     67      f  asymptomatic     120   229        2    129      2.6   \n",
      "3     37      f    nonanginal     130   250        0    187      3.5   \n",
      "4     41      m    nontypical     130   204        2    172      1.4   \n",
      "5     56      f    nontypical     120   236        0    178      0.8   \n",
      "6     62      m  asymptomatic     140   268        2    160      3.6   \n",
      "7     57      m  asymptomatic     120   354        0    163      0.6   \n",
      "8     63      f  asymptomatic     130   254        2    147      1.4   \n",
      "9     53      f  asymptomatic     140   203        2    155      3.1   \n",
      "10    57      f  asymptomatic     140   192        0    148      0.4   \n",
      "11    56      m    nontypical     140   294        2    153      1.3   \n",
      "12    56      f    nonanginal     130   256        2    142      0.6   \n",
      "13    44      f    nontypical     120   263        0    173      0.0   \n",
      "14    52      f    nonanginal     172   199        0    162      0.5   \n",
      "15    57      f    nonanginal     150   168        0    174      1.6   \n",
      "16    48      f    nontypical     110   229        0    168      1.0   \n",
      "17    54      f  asymptomatic     140   239        0    160      1.2   \n",
      "18    48      m    nonanginal     130   275        0    139      0.2   \n",
      "19    49      f    nontypical     130   266        0    171      0.6   \n",
      "20    64      f       typical     110   211        2    144      1.8   \n",
      "21    58      m       typical     150   283        2    162      1.0   \n",
      "22    58      f    nontypical     120   284        2    160      1.8   \n",
      "23    58      f    nonanginal     132   224        2    173      3.2   \n",
      "24    60      f  asymptomatic     130   206        2    132      2.4   \n",
      "25    50      m    nonanginal     120   219        0    158      1.6   \n",
      "26    58      m    nonanginal     120   340        0    172      0.0   \n",
      "27    66      m       typical     150   226        0    114      2.6   \n",
      "28    43      f  asymptomatic     150   247        0    171      1.5   \n",
      "29    40      f  asymptomatic     110   167        2    114      2.0   \n",
      "..   ...    ...           ...     ...   ...      ...    ...      ...   \n",
      "273   71      m  asymptomatic     112   149        0    125      1.6   \n",
      "274   59      f       typical     134   204        0    162      0.8   \n",
      "275   64      f       typical     170   227        2    155      0.6   \n",
      "276   66      m    nonanginal     146   278        2    152      0.0   \n",
      "277   39      m    nonanginal     138   220        0    152      0.0   \n",
      "278   57      f    nontypical     154   232        2    164      0.0   \n",
      "279   58      m  asymptomatic     130   197        0    131      0.6   \n",
      "280   57      f  asymptomatic     110   335        0    143      3.0   \n",
      "281   47      f    nonanginal     130   253        0    179      0.0   \n",
      "282   55      m  asymptomatic     128   205        1    130      2.0   \n",
      "283   35      f    nontypical     122   192        0    174      0.0   \n",
      "284   61      f  asymptomatic     148   203        0    161      0.0   \n",
      "285   58      f  asymptomatic     114   318        1    140      4.4   \n",
      "286   58      m  asymptomatic     170   225        2    146      2.8   \n",
      "287   58      f    nontypical     125   220        0    144      0.4   \n",
      "288   56      f    nontypical     130   221        2    163      0.0   \n",
      "289   56      f    nontypical     120   240        0    169      0.0   \n",
      "290   67      f    nonanginal     152   212        2    150      0.8   \n",
      "291   55      m    nontypical     132   342        0    166      1.2   \n",
      "292   44      f  asymptomatic     120   169        0    144      2.8   \n",
      "293   63      f  asymptomatic     140   187        2    144      4.0   \n",
      "294   63      m  asymptomatic     124   197        0    136      0.0   \n",
      "295   41      f    nontypical     120   157        0    182      0.0   \n",
      "296   59      f  asymptomatic     164   176        2     90      1.0   \n",
      "297   57      m  asymptomatic     140   241        0    123      0.2   \n",
      "298   45      f       typical     110   264        0    132      1.2   \n",
      "299   68      f  asymptomatic     144   193        0    141      3.4   \n",
      "300   57      f  asymptomatic     130   131        0    115      1.2   \n",
      "301   57      m    nontypical     130   236        2    174      0.0   \n",
      "302   38      f    nonanginal     138   175        0    173      0.0   \n",
      "\n",
      "           Thal  AHD  \n",
      "0         fixed   No  \n",
      "1        normal  Yes  \n",
      "2    reversable  Yes  \n",
      "3        normal   No  \n",
      "4        normal   No  \n",
      "5        normal   No  \n",
      "6        normal  Yes  \n",
      "7        normal   No  \n",
      "8    reversable  Yes  \n",
      "9    reversable  Yes  \n",
      "10        fixed   No  \n",
      "11       normal   No  \n",
      "12        fixed  Yes  \n",
      "13   reversable   No  \n",
      "14   reversable   No  \n",
      "15       normal   No  \n",
      "16   reversable  Yes  \n",
      "17       normal   No  \n",
      "18       normal   No  \n",
      "19       normal   No  \n",
      "20       normal   No  \n",
      "21       normal   No  \n",
      "22       normal  Yes  \n",
      "23   reversable  Yes  \n",
      "24   reversable  Yes  \n",
      "25       normal   No  \n",
      "26       normal   No  \n",
      "27       normal   No  \n",
      "28       normal   No  \n",
      "29   reversable  Yes  \n",
      "..          ...  ...  \n",
      "273      normal   No  \n",
      "274      normal  Yes  \n",
      "275  reversable   No  \n",
      "276      normal   No  \n",
      "277      normal   No  \n",
      "278      normal  Yes  \n",
      "279      normal   No  \n",
      "280  reversable  Yes  \n",
      "281      normal   No  \n",
      "282  reversable  Yes  \n",
      "283      normal   No  \n",
      "284  reversable  Yes  \n",
      "285       fixed  Yes  \n",
      "286       fixed  Yes  \n",
      "287  reversable   No  \n",
      "288  reversable   No  \n",
      "289      normal   No  \n",
      "290  reversable  Yes  \n",
      "291      normal   No  \n",
      "292       fixed  Yes  \n",
      "293  reversable  Yes  \n",
      "294      normal  Yes  \n",
      "295      normal   No  \n",
      "296       fixed  Yes  \n",
      "297  reversable  Yes  \n",
      "298  reversable  Yes  \n",
      "299  reversable  Yes  \n",
      "300  reversable  Yes  \n",
      "301      normal  Yes  \n",
      "302      normal   No  \n",
      "\n",
      "[303 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hearts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c- As you see, there are at least 3 catagorical features in the dataset (Gender, ChestPain, Thal). Let's ignore these categorical features for now, only keep the numerical features and build your feature matrix and label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  RestBP  Chol  RestECG  MaxHR  Oldpeak\n",
       "0   63     145   233        2    150      2.3\n",
       "1   67     160   286        2    108      1.5\n",
       "2   67     120   229        2    129      2.6\n",
       "3   37     130   250        0    187      3.5\n",
       "4   41     130   204        2    172      1.4"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Feature Matrix for hearts dataset:\n",
    "\n",
    "# Create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['Age', 'RestBP', 'Chol', 'RestECG', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = hearts_df[feature_cols]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 6)\n"
     ]
    }
   ],
   "source": [
    "# checking the size of Feature Matrix X:\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       No\n",
       "10      No\n",
       "20      No\n",
       "30      No\n",
       "40     Yes\n",
       "50      No\n",
       "60     Yes\n",
       "70      No\n",
       "80      No\n",
       "90      No\n",
       "100     No\n",
       "110    Yes\n",
       "120    Yes\n",
       "130     No\n",
       "140     No\n",
       "150     No\n",
       "160     No\n",
       "170    Yes\n",
       "180    Yes\n",
       "190     No\n",
       "200     No\n",
       "210     No\n",
       "220     No\n",
       "230     No\n",
       "240     No\n",
       "250     No\n",
       "260     No\n",
       "270    Yes\n",
       "280    Yes\n",
       "290    Yes\n",
       "300    Yes\n",
       "Name: AHD, dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = hearts_df['AHD']\n",
    "\n",
    "# checking the label vector by printing every 10 values\n",
    "y[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d- Split the dataset into testing and training sets with the following parameters:\n",
    "### test_size=0.3, random_state=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  RestBP  Chol  RestECG  MaxHR  Oldpeak\n",
      "245   67     120   237        0     71      1.0\n",
      "162   54     110   214        0    158      1.6\n",
      "10    57     140   192        0    148      0.4\n",
      "161   77     125   304        2    162      0.0\n",
      "73    65     110   248        2    158      0.6\n",
      "16    48     110   229        0    168      1.0\n",
      "180   48     124   274        2    166      0.5\n",
      "195   67     100   299        2    125      0.9\n",
      "200   50     110   254        2    159      0.0\n",
      "47    50     150   243        2    128      2.6\n",
      "101   34     118   182        2    174      0.0\n",
      "190   50     129   196        0    163      0.0\n",
      "79    58     150   270        2    111      0.8\n",
      "179   53     130   246        2    173      0.0\n",
      "269   42     130   180        0    150      0.0\n",
      "84    52     120   325        0    172      0.2\n",
      "77    51     140   308        2    142      1.5\n",
      "252   64     128   263        0    105      0.2\n",
      "38    55     132   353        0    132      1.2\n",
      "114   62     130   263        0     97      1.2\n",
      "225   34     118   210        0    192      0.7\n",
      "127   54     110   239        0    126      2.8\n",
      "78    48     130   245        2    180      0.2\n",
      "261   58     136   319        2    152      0.0\n",
      "67    54     150   232        2    165      1.6\n",
      "14    52     172   199        0    162      0.5\n",
      "123   55     140   217        0    111      5.6\n",
      "25    50     120   219        0    158      1.6\n",
      "65    60     145   282        2    142      2.8\n",
      "215   56     120   193        2    162      1.9\n",
      "..   ...     ...   ...      ...    ...      ...\n",
      "6     62     140   268        2    160      3.6\n",
      "274   59     134   204        0    162      0.8\n",
      "254   43     115   303        0    181      1.2\n",
      "74    44     110   197        2    177      0.0\n",
      "231   55     180   327        1    117      3.4\n",
      "233   74     120   269        2    121      0.2\n",
      "37    57     150   276        2    112      0.6\n",
      "3     37     130   250        0    187      3.5\n",
      "205   45     142   309        2    147      0.0\n",
      "163   58     100   248        2    122      1.0\n",
      "224   63     108   269        0    169      1.8\n",
      "170   70     160   269        0    112      2.9\n",
      "64    54     120   188        0    113      1.4\n",
      "238   49     134   271        0    162      0.0\n",
      "50    41     105   198        0    168      0.0\n",
      "23    58     132   224        2    173      3.2\n",
      "43    59     150   212        0    157      1.6\n",
      "196   69     160   234        2    131      0.1\n",
      "24    60     130   206        2    132      2.4\n",
      "300   57     130   131        0    115      1.2\n",
      "164   48     124   255        0    175      0.0\n",
      "134   43     122   213        0    165      0.2\n",
      "273   71     112   149        0    125      1.6\n",
      "286   58     170   225        2    146      2.8\n",
      "181   56     134   409        2    150      1.9\n",
      "248   52     125   212        0    168      1.0\n",
      "204   43     110   211        0    161      0.0\n",
      "40    65     150   225        2    114      1.0\n",
      "166   52     138   223        0    169      0.0\n",
      "236   56     130   283        2    103      1.6\n",
      "\n",
      "[91 rows x 6 columns]\n",
      "\n",
      "\n",
      "245    Yes\n",
      "162     No\n",
      "10      No\n",
      "161    Yes\n",
      "73     Yes\n",
      "16     Yes\n",
      "180    Yes\n",
      "195    Yes\n",
      "200     No\n",
      "47     Yes\n",
      "101     No\n",
      "190     No\n",
      "79     Yes\n",
      "179     No\n",
      "269     No\n",
      "84      No\n",
      "77      No\n",
      "252     No\n",
      "38     Yes\n",
      "114    Yes\n",
      "225     No\n",
      "127    Yes\n",
      "78      No\n",
      "261    Yes\n",
      "67      No\n",
      "14      No\n",
      "123    Yes\n",
      "25      No\n",
      "65     Yes\n",
      "215     No\n",
      "      ... \n",
      "6      Yes\n",
      "274    Yes\n",
      "254     No\n",
      "74     Yes\n",
      "231    Yes\n",
      "233     No\n",
      "37     Yes\n",
      "3       No\n",
      "205    Yes\n",
      "163     No\n",
      "224    Yes\n",
      "170    Yes\n",
      "64     Yes\n",
      "238     No\n",
      "50      No\n",
      "23     Yes\n",
      "43      No\n",
      "196     No\n",
      "24     Yes\n",
      "300    Yes\n",
      "164     No\n",
      "134     No\n",
      "273     No\n",
      "286    Yes\n",
      "181    Yes\n",
      "248    Yes\n",
      "204     No\n",
      "40     Yes\n",
      "166     No\n",
      "236    Yes\n",
      "Name: AHD, Length: 91, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Picks 30% of data samples for testing set and 70% for training set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 6)\n",
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the training set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 6)\n",
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e- Use KNN (with k=5), Decision Tree, and Logistic Regression Classifiers to predict Heart Disease based on the training/testing datasets that you built in part (d). Then check, compare, and report the accuracy of these 3 classifiers. Which one is the best? Which one is the worst?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiating an \"object\" of KNeighborsClassifier \"class\" with k=5:\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes'\n",
      " 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes'\n",
      " 'No' 'No' 'No' 'No' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'No'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'No' 'No' 'Yes'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "\n",
    "print(y_predict_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Accuracy Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626373626374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_predict_knn)\n",
    "\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# \"my_decisiontree\" is instantiated as an \"object\" of DecisionTreeCLassifier \"class\"\n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "my_decisiontree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'No'\n",
      " 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'No' 'No'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No'\n",
      " 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes'\n",
      " 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes'\n",
      " 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "y_predict_dt = my_decisiontree.predict(X_test)\n",
    "\n",
    "print(y_predict_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Accuracy Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659340659341\n"
     ]
    }
   ],
   "source": [
    "accuracy_dt = accuracy_score(y_test, y_predict_dt)\n",
    "\n",
    "print(accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# \"my_decisiontree\" is instantiated as an \"object\" of DecisionTreeCLassifier \"class\"\n",
    "\n",
    "my_logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "my_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'No' 'No' 'No' 'No' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No'\n",
      " 'No' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes'\n",
      " 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'No'\n",
      " 'No' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes'\n",
      " 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes'\n",
      " 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes'\n",
      " 'Yes' 'No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "y_predict_lr = my_logreg.predict(X_test)\n",
    "\n",
    "print(y_predict_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Accuracy Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725274725275\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr = accuracy_score(y_test, y_predict_lr)\n",
    "\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:                  0.626373626374\n",
      "Decision Tree:        0.659340659341\n",
      "Logistic Regression:  0.725274725275\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:                 \", accuracy_knn)\n",
    "print(\"Decision Tree:       \", accuracy_dt)\n",
    "print(\"Logistic Regression: \", accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression is the best. Decision Tree is the worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f- Now, we want to use the categorical feature as well! To this end, we have to perform a feature engineering process called OneHotEncoding for the categorical features.\n",
    "\n",
    "### To do this, each categorical feature should be replaced with dummy columns in the feature table (one column for each possible value of a categorical feature), and then encode it in a binary manner such that only one of the dummy colums can take \"1\" at a time (and zero for the rest).\n",
    "\n",
    "### For example, \"Gender\" can take two values \"m\" and \"f\". Thus, we need to replace this feature (in the feature table) by 2 colums titled \"m\" and \"f\".\n",
    "- Wherever we have a male subject, we can put \"1\" and \"0\" in the columns \"m\" and \"f\".\n",
    "- Wherever we have a female subject, we can put \"0\" and \"1\" in the columns \"m\" and \"f\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Gender', 'ChestPain', 'RestBP', 'Chol', 'RestECG', 'MaxHR',\n",
      "       'Oldpeak', 'Thal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hearts_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Gender     ChestPain  RestBP  Chol  RestECG  MaxHR  Oldpeak  \\\n",
      "0   63      f       typical     145   233        2    150      2.3   \n",
      "1   67      f  asymptomatic     160   286        2    108      1.5   \n",
      "2   67      f  asymptomatic     120   229        2    129      2.6   \n",
      "3   37      f    nonanginal     130   250        0    187      3.5   \n",
      "4   41      m    nontypical     130   204        2    172      1.4   \n",
      "\n",
      "         Thal  AHD  \n",
      "0       fixed   No  \n",
      "1      normal  Yes  \n",
      "2  reversable  Yes  \n",
      "3      normal   No  \n",
      "4      normal   No  \n",
      "\n",
      "\n",
      "   Age  RestBP  Chol  RestECG  MaxHR  Oldpeak  Gender_f  Gender_m  \\\n",
      "0   63     145   233        2    150      2.3         1         0   \n",
      "1   67     160   286        2    108      1.5         1         0   \n",
      "2   67     120   229        2    129      2.6         1         0   \n",
      "3   37     130   250        0    187      3.5         1         0   \n",
      "4   41     130   204        2    172      1.4         0         1   \n",
      "\n",
      "   ChestPain_asymptomatic  ChestPain_nonanginal  ChestPain_nontypical  \\\n",
      "0                       0                     0                     0   \n",
      "1                       1                     0                     0   \n",
      "2                       1                     0                     0   \n",
      "3                       0                     1                     0   \n",
      "4                       0                     0                     1   \n",
      "\n",
      "   ChestPain_typical  Thal_fixed  Thal_normal  Thal_reversable  AHD  \n",
      "0                  1           1            0                0   No  \n",
      "1                  0           0            1                0  Yes  \n",
      "2                  0           0            0                1  Yes  \n",
      "3                  0           0            1                0   No  \n",
      "4                  0           0            1                0   No  \n"
     ]
    }
   ],
   "source": [
    "# OneHotEncoding using pd.get_dummies\n",
    "\n",
    "# Categorical features: (Gender, ChestPain, Thal)\n",
    "encoded_hearts_df = pd.get_dummies(hearts_df, columns = ['Gender', 'ChestPain', 'Thal'])\n",
    "\n",
    "# Re-order columns so AHD is last\n",
    "cols = encoded_hearts_df.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('AHD')))\n",
    "encoded_hearts_df = encoded_hearts_df.reindex(columns = cols)\n",
    "\n",
    "print(hearts_df.head())\n",
    "print('\\n')\n",
    "print(encoded_hearts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g- Repeat parts (d) and (e) with the new dataset that you built in part (f). How does the prediction accuracy change for each method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  RestBP  Chol  RestECG  MaxHR  Oldpeak  Gender_f  Gender_m  \\\n",
      "245   67     120   237        0     71      1.0         1         0   \n",
      "162   54     110   214        0    158      1.6         0         1   \n",
      "10    57     140   192        0    148      0.4         1         0   \n",
      "161   77     125   304        2    162      0.0         1         0   \n",
      "73    65     110   248        2    158      0.6         1         0   \n",
      "\n",
      "     ChestPain_asymptomatic  ChestPain_nonanginal  ChestPain_nontypical  \\\n",
      "245                       1                     0                     0   \n",
      "162                       0                     1                     0   \n",
      "10                        1                     0                     0   \n",
      "161                       1                     0                     0   \n",
      "73                        1                     0                     0   \n",
      "\n",
      "     ChestPain_typical  Thal_fixed  Thal_normal  Thal_reversable  \n",
      "245                  0           0            1                0  \n",
      "162                  0           0            1                0  \n",
      "10                   0           1            0                0  \n",
      "161                  0           0            1                0  \n",
      "73                   0           1            0                0  \n",
      "\n",
      "\n",
      "245    Yes\n",
      "162     No\n",
      "10      No\n",
      "161    Yes\n",
      "73     Yes\n",
      "Name: AHD, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Picks 30% of data samples for testing set and 70% for training set\n",
    "# feature_cols includes all columns excluding AHD\n",
    "feature_cols = cols[:-1]\n",
    "X = encoded_hearts_df[feature_cols]\n",
    "y = encoded_hearts_df['AHD']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "print(X_test.head())\n",
    "print('\\n')\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626373626374\n"
     ]
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Testing on the testing set:\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "\n",
    "# KNN Accuracy Evaluation\n",
    "accuracy_knn = accuracy_score(y_test, y_predict_knn)\n",
    "\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736263736264\n"
     ]
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "\n",
    "# Testing on the testing set:\n",
    "y_predict_dt = my_decisiontree.predict(X_test)\n",
    "\n",
    "# Decision Tree Accuracy Evaluation\n",
    "accuracy_dt = accuracy_score(y_test, y_predict_dt)\n",
    "\n",
    "print(accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846153846154\n"
     ]
    }
   ],
   "source": [
    "# Training only on the training set using the method \"fit\" \n",
    "# of the object along with training dataset and labels to train the model.\n",
    "my_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Testing on the testing set:\n",
    "y_predict_lr = my_logreg.predict(X_test)\n",
    "\n",
    "# Logistic Regression Accuracy Evaluation\n",
    "accuracy_lr = accuracy_score(y_test, y_predict_lr)\n",
    "\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:                  0.626373626374\n",
      "Decision Tree:        0.736263736264\n",
      "Logistic Regression:  0.846153846154\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:                 \", accuracy_knn)\n",
    "print(\"Decision Tree:       \", accuracy_dt)\n",
    "print(\"Logistic Regression: \", accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN accuracy is unchanged. Decision Tree and Logistic Regression have improved accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h- Now, repeat part (e) with the new dataset that you built in part (f), this time using Cross-Validation. Thus, rather than splitting the dataset into testing and training, use 10-fold Cross-Validation to evaluate the classification methods and report the final prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model_selection as cross_validation is deppreciated\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 15)\n",
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "# Feature Matrix:\n",
    "X = encoded_hearts_df[feature_cols]\n",
    "\n",
    "# Label Vector:\n",
    "y = encoded_hearts_df['AHD']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70967742  0.67741935  0.58064516  0.61290323  0.66666667  0.46666667\n",
      "  0.76666667  0.66666667  0.53333333  0.75862069]\n"
     ]
    }
   ],
   "source": [
    "# Applying 10-fold cross validation with \"KNN\" classifier:\n",
    "accuracy_list = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643926585095\n"
     ]
    }
   ],
   "source": [
    "# use average of accuracy values as final result\n",
    "knn_cv = accuracy_list.mean()\n",
    "\n",
    "print(knn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80645161  0.70967742  0.80645161  0.70967742  0.83333333  0.73333333\n",
      "  0.6         0.53333333  0.66666667  0.65517241]\n"
     ]
    }
   ],
   "source": [
    "# Applying 10-fold cross validation with \"Decision Tree\" classifier:\n",
    "accuracy_list = cross_val_score(my_decisiontree, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705409714498\n"
     ]
    }
   ],
   "source": [
    "# use average of accuracy values as final result\n",
    "dt_cv = accuracy_list.mean()\n",
    "\n",
    "print(dt_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77419355  0.80645161  0.87096774  0.87096774  0.9         0.66666667\n",
      "  0.8         0.83333333  0.8         0.79310345]\n"
     ]
    }
   ],
   "source": [
    "# Applying 10-fold cross validation with \"Logistic Regression\" classifier:\n",
    "accuracy_list = cross_val_score(my_logreg, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811568409344\n"
     ]
    }
   ],
   "source": [
    "# use average of accuracy values as final result\n",
    "lr_cv = accuracy_list.mean()\n",
    "\n",
    "print(lr_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:                  0.643926585095\n",
      "Decision Tree:        0.705409714498\n",
      "Logistic Regression:  0.811568409344\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:                 \", knn_cv)\n",
    "print(\"Decision Tree:       \", dt_cv)\n",
    "print(\"Logistic Regression: \", lr_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
